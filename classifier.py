import os
import io
import json
import base64
from typing import Tuple, List, Dict, Optional

import numpy as np
from PIL import Image

import torch
import requests
import rasterio
from rasterio.io import MemoryFile
from rasterio.features import shapes
from rasterio.transform import from_bounds


class PotsdamSegmentationClassifier:
    """Ð¡ÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ‚Ð¾Ñ€ Ð°ÑÑ€Ð¾Ñ„Ð¾Ñ‚Ð¾ÑÐ½Ð¸Ð¼ÐºÐ¾Ð² Potsdam Ð½Ð° PyTorch Ñ Ð°Ð²Ñ‚Ð¾Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ñ Google Drive"""

    def __init__(
        self,
        model_path: str = "models/best_unetpp_efficientnetb0.pth",
        tile: int = 256,
        overlap: int = 32,
        batch_size: int = 8,
        google_drive_file_id: Optional[str] = None,
    ):
        self.model_path = model_path
        self.tile = tile
        self.overlap = overlap
        self.batch_size = batch_size
        self.model = None
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.google_drive_file_id = google_drive_file_id

        # Ð›ÐµÐ³ÐµÐ½Ð´Ð° Potsdam (Ñ„Ð¸ÐºÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ñ†Ð²ÐµÑ‚Ð°)
        self.class_colors = {
            0: (0, 0, 0),          # Background
            1: (139, 69, 19),      # Buildings
            2: (128, 128, 128),    # Roads
            3: (0, 128, 0),        # Low vegetation
            4: (0, 255, 0),        # Trees
            5: (128, 0, 128),      # Cars
        }
        self.class_names = {
            0: "Background",
            1: "Building",
            2: "Road",
            3: "Low vegetation",
            4: "Tree",
            5: "Car",
        }

        os.makedirs(os.path.dirname(self.model_path) or ".", exist_ok=True)

    # ---------- Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ñ Google Drive ----------
    def _download_model_from_gdrive(self, file_id: str, dest_path: str) -> None:
        session = requests.Session()
        base_url = "https://docs.google.com/uc?export=download"

        response = session.get(base_url, params={"id": file_id}, stream=True)
        token = None
        for k, v in response.cookies.items():
            if k.startswith("download_warning"):
                token = v
                break

        if token:
            response = session.get(base_url, params={"id": file_id, "confirm": token}, stream=True)

        if response.status_code != 200:
            raise RuntimeError(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸: HTTP {response.status_code}")

        with open(dest_path, "wb") as f:
            for chunk in response.iter_content(32768):
                if chunk:
                    f.write(chunk)

    def ensure_model(self) -> None:
        if not os.path.exists(self.model_path):
            if not self.google_drive_file_id:
                raise RuntimeError("Ð¤Ð°Ð¹Ð» Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ Ð¸ google_drive_file_id Ð½Ðµ Ð·Ð°Ð´Ð°Ð½.")
            print("ðŸ”„ ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð° â€” Ð·Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ñ Google Drive...")
            self._download_model_from_gdrive(self.google_drive_file_id, self.model_path)
            print(f"âœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°: {self.model_path}")

    # ---------- Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸ ----------
    def load_model(self, model_class):
        if self.model is not None:
            return
        if model_class is None:
            raise RuntimeError("Ð”Ð»Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð½ÑƒÐ¶ÐµÐ½ model_class")

        self.ensure_model()

        m = model_class()
        checkpoint = torch.load(self.model_path, map_location=self.device)

        if isinstance(checkpoint, dict) and "model_state_dict" in checkpoint:
            sd = checkpoint["model_state_dict"]
        else:
            sd = checkpoint

        try:
            m.load_state_dict(sd, strict=True)
        except RuntimeError as e:
            print("âš ï¸ ÐÐµÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ðµ state_dict Ð¿Ñ€Ð¸ strict=True.\n", str(e))
            m.load_state_dict(sd, strict=False)

        self.model = m
        self.model.eval()
        self.model.to(self.device)

    # ---------- Ð’Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ ----------
    def process_raster(self, file_bytes: bytes) -> Tuple[np.ndarray, dict, object, object]:
        """
        Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚:
        - data: np.ndarray [H, W, 3] float32 Ð² Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½Ðµ [0,1]
        - profile: Ð¸ÑÑ…Ð¾Ð´Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ñ„Ð¸Ð»ÑŒ Ñ€Ð°ÑÑ‚Ñ€Ð¾Ð²Ð¾Ð³Ð¾ Ñ„Ð°Ð¹Ð»Ð° (Ð¸Ð»Ð¸ Ð·Ð°Ð³Ð»ÑƒÑˆÐºÐ°)
        - transform: Ð°Ñ„Ñ„Ð¸Ð½Ð½Ð¾Ðµ Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ (Ð¸Ð»Ð¸ Ð·Ð°Ð³Ð»ÑƒÑˆÐºÐ° Ð´Ð»Ñ PNG/JPG)
        - crs: ÑÐ¸ÑÑ‚ÐµÐ¼Ð° ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚ (None Ð´Ð»Ñ PNG/JPG)
        """
        try:
            with MemoryFile(file_bytes) as memfile:
                with memfile.open() as src:
                    profile = src.profile.copy()
                    transform, crs = src.transform, src.crs
                    count = profile.get("count", 1)
                    if count >= 3:
                        data = src.read([1, 2, 3]).transpose(1, 2, 0).astype(np.float32)
                    else:
                        one = src.read(1).astype(np.float32)
                        data = np.stack([one, one, one], axis=-1)
                    data = np.nan_to_num(data, nan=0.0, posinf=255.0, neginf=0.0)
                    maxv = np.max(data) if np.isfinite(np.max(data)) else 255.0
                    data = (data / max(1.0, maxv)).clip(0.0, 1.0)
                    return data, profile, transform, crs
        except Exception:
            img = Image.open(io.BytesIO(file_bytes)).convert("RGB")
            data = np.array(img, dtype=np.float32) / 255.0
            h, w = data.shape[:2]
            profile = {"driver": "GTiff", "dtype": "uint8", "count": 1,
                       "height": h, "width": w, "compress": "lzw"}
            transform = from_bounds(0, 0, w, h, w, h)
            return data, profile, transform, None

    # ---------- Ð¢Ð°Ð¹Ð»Ð¾Ð²ÐºÐ° ----------
    def _to_tensor(self, img: np.ndarray) -> torch.Tensor:
        return torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0)

    def _coords(self, H: int, W: int) -> List[Tuple[int, int]]:
        stride = max(1, self.tile - self.overlap)
        xs = list(range(0, max(W - self.tile, 0) + 1, stride))
        ys = list(range(0, max(H - self.tile, 0) + 1, stride))
        if len(xs) == 0: xs = [0]
        if len(ys) == 0: ys = [0]
        if xs[-1] != max(W - self.tile, 0): xs.append(max(W - self.tile, 0))
        if ys[-1] != max(H - self.tile, 0): ys.append(max(H - self.tile, 0))
        return [(y, x) for y in ys for x in xs]

    def segment(self, data: np.ndarray) -> np.ndarray:
        if self.model is None:
            raise RuntimeError("ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð½Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°")

        H, W, _ = data.shape
        coords = self._coords(H, W)
        class_map = np.zeros((H, W), dtype=np.uint8)

        for (y, x) in coords:
            patch = data[y:y + self.tile, x:x + self.tile, :]
            inp = self._to_tensor(patch).to(self.device)
            with torch.no_grad():
                out = self.model(inp)  # Ð¾Ð¶Ð¸Ð´Ð°ÐµÑ‚ÑÑ [B, C, H, W]
                probs = torch.softmax(out, dim=1).cpu().numpy()
                pred = probs.argmax(axis=1)[0]  # [H, W]
            h, w = patch.shape[:2]
            class_map[y:y + h, x:x + w] = pred[:h, :w]

        return class_map

    # ---------- Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ ----------
    def _visualize_bytes(self, class_map: np.ndarray) -> bytes:
        h, w = class_map.shape
        rgb = np.zeros((h, w, 3), dtype=np.uint8)
        for cid, color in self.class_colors.items():
            rgb[class_map == cid] = color
        img = Image.fromarray(rgb)
        buf = io.BytesIO()
        img.save(buf, format="PNG", optimize=True)
        buf.seek(0)
        return buf.getvalue()

    def _write_geotiff_bytes(self, class_map: np.ndarray, profile: dict, transform: object, crs: object) -> bytes:
        out_profile = profile.copy()
        out_profile.update({"count": 1, "dtype": "uint8", "compress": "lzw"})
        out_profile.pop("nodata", None)
        with MemoryFile() as memfile:
            with memfile.open(**out_profile) as dst:
                dst.write(class_map.astype(np.uint8), 1)
                if transform is not None:
                    dst.transform = transform
                if crs is not None:
                    dst.crs = crs
            return memfile.read()

    def _write_tiff_bytes(self, class_map: np.ndarray) -> bytes:
        img = Image.fromarray(class_map.astype(np.uint8), mode="L")
        buf = io.BytesIO()
        img.save(buf, format="TIFF", compression="tiff_lzw")
        buf.seek(0)
        return buf.getvalue()

    def _vectorize_geojson(self, class_map: np.ndarray, transform: object, active_classes: Optional[List[int]]) -> str:
        """
        Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ GeoJSON Ñ Ð¿Ð¾Ð»Ð¸Ð³Ð¾Ð½Ð°Ð¼Ð¸ Ð¿Ð¾ Ð¼Ð°ÑÐºÐµ.
        Ð”Ð»Ñ PNG/JPG (crs=None) Ð³ÐµÐ¾Ð¼ÐµÑ‚Ñ€Ð¸Ñ Ð±ÑƒÐ´ÐµÑ‚ Ð² Ð¿Ð¸ÐºÑÐµÐ»ÑŒÐ½Ñ‹Ñ… ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ð°Ñ… (Ð¿Ð¾ transform-Ð·Ð°Ð³Ð»ÑƒÑˆÐºÐµ).
        """
        mask = class_map.astype(np.int32)
        features = []

        # Ð•ÑÐ»Ð¸ ÑƒÐºÐ°Ð·Ð°Ð½Ñ‹ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ ÐºÐ»Ð°ÑÑÑ‹ â€” Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¿Ð¾Ð»Ð¸Ð³Ð¾Ð½Ñ‹ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð´Ð»Ñ Ð½Ð¸Ñ…
        target_classes = active_classes if active_classes else sorted(self.class_names.keys())

        for cid in target_classes:
            # Ð‘Ð¸Ð½Ð°Ñ€Ð½Ð°Ñ Ð¼Ð°ÑÐºÐ° Ð¿Ð¾ ÐºÐ»Ð°ÑÑÑƒ
            bin_mask = (mask == cid).astype(np.uint8)
            if bin_mask.sum() == 0:
                continue

            for geom, val in shapes(bin_mask, transform=transform):
                if val != 1:
                    continue
                features.append({
                    "type": "Feature",
                    "geometry": geom,
                    "properties": {
                        "class_id": int(cid),
                        "class_name": self.class_names.get(cid, str(cid)),
                        "color": self.class_colors.get(cid, (0, 0, 0))
                    }
                })

        geojson = {
            "type": "FeatureCollection",
            "features": features
        }
        return json.dumps(geojson)

    # ---------- ÐšÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ ----------
    def segment_all(self, file_bytes: bytes, active_classes: Optional[List[int]] = None) -> Dict[str, object]:
        """
        Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ:
        - visualization: base64 PNG Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ (Ð¿Ð¾ Ñ†Ð²ÐµÑ‚Ð°Ð¼)
        - geotiff: base64 GeoTIFF (ÐºÐ»Ð°ÑÑÑ‹ ÐºÐ°Ðº uint8)
        - tiff: base64 TIFF (uint8 Ð¼Ð°ÑÐºÐ°)
        - geojson: ÑÑ‚Ñ€Ð¾ÐºÐ° JSON Ñ Ð¿Ð¾Ð»Ð¸Ð³Ð¾Ð½Ð°Ð¼Ð¸ (Ð¿Ð¾ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¼ ÐºÐ»Ð°ÑÑÐ°Ð¼)
        - stats: ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾ ÐºÐ»Ð°ÑÑÐ°Ð¼
        """
        # 1) ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…
        data, profile, transform, crs = self.process_raster(file_bytes)

        # 2) Ð¡ÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ
        class_map = self.segment(data)  # [H, W] uint8

        # 3) Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ (PNG, RGB)
        vis_bytes = self._visualize_bytes(class_map)
        vis_b64 = base64.b64encode(vis_bytes).decode("utf-8")

        # 4) GeoTIFF (uint8 ÐºÐ»Ð°ÑÑÑ‹ + Ð³ÐµÐ¾Ð¿Ñ€Ð¸Ð²ÑÐ·ÐºÐ°)
        geotiff_bytes = self._write_geotiff_bytes(class_map, profile, transform, crs)
        geotiff_b64 = base64.b64encode(geotiff_bytes).decode("utf-8")

        # 5) TIFF (uint8 Ð¼Ð°ÑÐºÐ°, Ð±ÐµÐ· Ð³ÐµÐ¾Ð¿Ñ€Ð¸Ð²ÑÐ·ÐºÐ¸)
        tiff_bytes = self._write_tiff_bytes(class_map)
        tiff_b64 = base64.b64encode(tiff_bytes).decode("utf-8")

        # 6) GeoJSON (Ð²ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¿Ð¾ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¼ ÐºÐ»Ð°ÑÑÐ°Ð¼)
        geojson_str = self._vectorize_geojson(class_map, transform, active_classes)

        # 7) Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
        stats = {}
        total = int(class_map.size)
        for cid, name in self.class_names.items():
            pixels = int((class_map == cid).sum())
            percent = round(100.0 * pixels / total, 4) if total > 0 else 0.0
            stats[int(cid)] = {
                "name": name,
                "pixels": pixels,
                "percent": percent
            }

        return {
            "visualization": vis_b64,
            "geotiff": geotiff_b64,
            "tiff": tiff_b64,
            "geojson": geojson_str,
            "stats": stats
        
